{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e03f453-f2f9-4224-b865-12438b1eaec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\myenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import optuna\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f3cf505-495a-4041-b720-5615acb6063c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optuna\n",
      "  Downloading optuna-4.5.0-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting alembic>=1.5.0 (from optuna)\n",
      "  Downloading alembic-1.16.5-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting colorlog (from optuna)\n",
      "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy in f:\\myenv\\lib\\site-packages (from optuna) (2.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in f:\\myenv\\lib\\site-packages (from optuna) (25.0)\n",
      "Collecting sqlalchemy>=1.4.2 (from optuna)\n",
      "  Downloading sqlalchemy-2.0.43-cp311-cp311-win_amd64.whl.metadata (9.8 kB)\n",
      "Collecting tqdm (from optuna)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: PyYAML in f:\\myenv\\lib\\site-packages (from optuna) (6.0.2)\n",
      "Collecting Mako (from alembic>=1.5.0->optuna)\n",
      "  Downloading mako-1.3.10-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.12 in f:\\myenv\\lib\\site-packages (from alembic>=1.5.0->optuna) (4.15.0)\n",
      "Collecting greenlet>=1 (from sqlalchemy>=1.4.2->optuna)\n",
      "  Downloading greenlet-3.2.4-cp311-cp311-win_amd64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: colorama in f:\\myenv\\lib\\site-packages (from colorlog->optuna) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in f:\\myenv\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
      "Downloading optuna-4.5.0-py3-none-any.whl (400 kB)\n",
      "Downloading alembic-1.16.5-py3-none-any.whl (247 kB)\n",
      "Downloading sqlalchemy-2.0.43-cp311-cp311-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 0.5/2.1 MB 3.4 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.3/2.1 MB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 3.3 MB/s eta 0:00:00\n",
      "Downloading greenlet-3.2.4-cp311-cp311-win_amd64.whl (299 kB)\n",
      "Downloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
      "Downloading mako-1.3.10-py3-none-any.whl (78 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm, Mako, greenlet, colorlog, sqlalchemy, alembic, optuna\n",
      "\n",
      "   ---------------------------------------- 0/7 [tqdm]\n",
      "   ---------------------------------------- 0/7 [tqdm]\n",
      "   ---------------------------------------- 0/7 [tqdm]\n",
      "   ---------------------------------------- 0/7 [tqdm]\n",
      "   ---------------------------------------- 0/7 [tqdm]\n",
      "   ----- ---------------------------------- 1/7 [Mako]\n",
      "   ----- ---------------------------------- 1/7 [Mako]\n",
      "   ----- ---------------------------------- 1/7 [Mako]\n",
      "   ----- ---------------------------------- 1/7 [Mako]\n",
      "   ----- ---------------------------------- 1/7 [Mako]\n",
      "   ----- ---------------------------------- 1/7 [Mako]\n",
      "   ----- ---------------------------------- 1/7 [Mako]\n",
      "   ----------- ---------------------------- 2/7 [greenlet]\n",
      "   ----------- ---------------------------- 2/7 [greenlet]\n",
      "   ----------- ---------------------------- 2/7 [greenlet]\n",
      "   ----------- ---------------------------- 2/7 [greenlet]\n",
      "   ----------- ---------------------------- 2/7 [greenlet]\n",
      "   ----------- ---------------------------- 2/7 [greenlet]\n",
      "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
      "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
      "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
      "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
      "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
      "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
      "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
      "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
      "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
      "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
      "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
      "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
      "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
      "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
      "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
      "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
      "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
      "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
      "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
      "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
      "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
      "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
      "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
      "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
      "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
      "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
      "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
      "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
      "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
      "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
      "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
      "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
      "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
      "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
      "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
      "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
      "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
      "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
      "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
      "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
      "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
      "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
      "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
      "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
      "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
      "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
      "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
      "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
      "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
      "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
      "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
      "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
      "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
      "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
      "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
      "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
      "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
      "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
      "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
      "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
      "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
      "   ---------------------------- ----------- 5/7 [alembic]\n",
      "   ---------------------------- ----------- 5/7 [alembic]\n",
      "   ---------------------------- ----------- 5/7 [alembic]\n",
      "   ---------------------------- ----------- 5/7 [alembic]\n",
      "   ---------------------------- ----------- 5/7 [alembic]\n",
      "   ---------------------------- ----------- 5/7 [alembic]\n",
      "   ---------------------------- ----------- 5/7 [alembic]\n",
      "   ---------------------------- ----------- 5/7 [alembic]\n",
      "   ---------------------------- ----------- 5/7 [alembic]\n",
      "   ---------------------------- ----------- 5/7 [alembic]\n",
      "   ---------------------------- ----------- 5/7 [alembic]\n",
      "   ---------------------------- ----------- 5/7 [alembic]\n",
      "   ---------------------------- ----------- 5/7 [alembic]\n",
      "   ---------------------------- ----------- 5/7 [alembic]\n",
      "   ---------------------------------- ----- 6/7 [optuna]\n",
      "   ---------------------------------- ----- 6/7 [optuna]\n",
      "   ---------------------------------- ----- 6/7 [optuna]\n",
      "   ---------------------------------- ----- 6/7 [optuna]\n",
      "   ---------------------------------- ----- 6/7 [optuna]\n",
      "   ---------------------------------- ----- 6/7 [optuna]\n",
      "   ---------------------------------- ----- 6/7 [optuna]\n",
      "   ---------------------------------- ----- 6/7 [optuna]\n",
      "   ---------------------------------- ----- 6/7 [optuna]\n",
      "   ---------------------------------- ----- 6/7 [optuna]\n",
      "   ---------------------------------- ----- 6/7 [optuna]\n",
      "   ---------------------------------- ----- 6/7 [optuna]\n",
      "   ---------------------------------- ----- 6/7 [optuna]\n",
      "   ---------------------------------- ----- 6/7 [optuna]\n",
      "   ---------------------------------- ----- 6/7 [optuna]\n",
      "   ---------------------------------- ----- 6/7 [optuna]\n",
      "   ---------------------------------- ----- 6/7 [optuna]\n",
      "   ---------------------------------- ----- 6/7 [optuna]\n",
      "   ---------------------------------- ----- 6/7 [optuna]\n",
      "   ---------------------------------- ----- 6/7 [optuna]\n",
      "   ---------------------------------- ----- 6/7 [optuna]\n",
      "   ---------------------------------- ----- 6/7 [optuna]\n",
      "   ---------------------------------- ----- 6/7 [optuna]\n",
      "   ---------------------------------- ----- 6/7 [optuna]\n",
      "   ---------------------------------- ----- 6/7 [optuna]\n",
      "   ---------------------------------- ----- 6/7 [optuna]\n",
      "   ---------------------------------- ----- 6/7 [optuna]\n",
      "   ---------------------------------- ----- 6/7 [optuna]\n",
      "   ---------------------------------- ----- 6/7 [optuna]\n",
      "   ---------------------------------- ----- 6/7 [optuna]\n",
      "   ---------------------------------- ----- 6/7 [optuna]\n",
      "   ---------------------------------- ----- 6/7 [optuna]\n",
      "   ---------------------------------- ----- 6/7 [optuna]\n",
      "   ---------------------------------- ----- 6/7 [optuna]\n",
      "   ---------------------------------- ----- 6/7 [optuna]\n",
      "   ---------------------------------------- 7/7 [optuna]\n",
      "\n",
      "Successfully installed Mako-1.3.10 alembic-1.16.5 colorlog-6.9.0 greenlet-3.2.4 optuna-4.5.0 sqlalchemy-2.0.43 tqdm-4.67.1\n"
     ]
    }
   ],
   "source": [
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2d3a9c-7dfd-445e-95fb-b04977d14edc",
   "metadata": {},
   "source": [
    "<h3> Load Synthetically Generated Data <h3/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14d39102-72c9-4051-afbb-055e5bd0a32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Generate synthetic dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6c014f2-cea4-4e94-af09-e073d9ec3835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 20)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70e263a2-2645-42df-9604-f8a753eff549",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.50363664, -1.51368248, -0.46907062,  1.90176571, -0.87064279,\n",
       "        1.82004715,  1.66291365,  1.29105223, -0.16713608, -1.04718436,\n",
       "        1.43003039,  0.20104766,  1.27577182, -1.13260729,  1.75008532,\n",
       "       -1.4089039 ,  0.03301588, -0.80340946, -1.31410638,  1.41209637])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e184f4a5-3116-41cb-8461-16c7912daede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8275d323-406b-4125-ac3e-3d3abaede37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to PyTorch tensors\n",
    "X_train, y_train = torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.long)\n",
    "X_val, y_val = torch.tensor(X_val, dtype=torch.float32), torch.tensor(y_val, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ef2e19-73df-4cd7-8fb4-30454989d40b",
   "metadata": {},
   "source": [
    "<h3> Define a Neural Network <h3/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c449fbf8-6f3f-458e-8a97-bde06d00328e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 2)  # Output layer for binary classification\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6aca46-abdb-4c50-beac-2629a7dd3e38",
   "metadata": {},
   "source": [
    "### Perform Hyperparameter tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "23dcf781-b25e-4c4d-83e8-43db10d3edad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-01 11:05:13,836] A new study created in memory with name: no-name-86089da0-7bd3-4856-bc9e-b23104fc98a6\n",
      "C:\\Users\\MY PC\\AppData\\Local\\Temp\\ipykernel_8016\\3461048078.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-1)\n",
      "[I 2025-09-01 11:05:20,921] Trial 0 finished with value: 0.845 and parameters: {'learning_rate': 0.0053566260449788815, 'hidden_dim': 122}. Best is trial 0 with value: 0.845.\n",
      "C:\\Users\\MY PC\\AppData\\Local\\Temp\\ipykernel_8016\\3461048078.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-1)\n",
      "[I 2025-09-01 11:05:22,834] Trial 1 finished with value: 0.83 and parameters: {'learning_rate': 0.0006005767797884673, 'hidden_dim': 76}. Best is trial 0 with value: 0.845.\n",
      "[I 2025-09-01 11:05:24,766] Trial 2 finished with value: 0.835 and parameters: {'learning_rate': 0.00035425424054145966, 'hidden_dim': 33}. Best is trial 0 with value: 0.845.\n",
      "[I 2025-09-01 11:05:26,600] Trial 3 finished with value: 0.825 and parameters: {'learning_rate': 0.00487994378445769, 'hidden_dim': 77}. Best is trial 0 with value: 0.845.\n",
      "[I 2025-09-01 11:05:28,557] Trial 4 finished with value: 0.82 and parameters: {'learning_rate': 0.0031672470943249977, 'hidden_dim': 84}. Best is trial 0 with value: 0.845.\n",
      "[I 2025-09-01 11:05:30,735] Trial 5 finished with value: 0.82 and parameters: {'learning_rate': 0.0492150983864389, 'hidden_dim': 19}. Best is trial 0 with value: 0.845.\n",
      "[I 2025-09-01 11:05:32,494] Trial 6 finished with value: 0.83 and parameters: {'learning_rate': 0.015535469840483864, 'hidden_dim': 86}. Best is trial 0 with value: 0.845.\n",
      "[I 2025-09-01 11:05:34,727] Trial 7 finished with value: 0.85 and parameters: {'learning_rate': 0.0007223838653765844, 'hidden_dim': 79}. Best is trial 7 with value: 0.85.\n",
      "[I 2025-09-01 11:05:36,702] Trial 8 finished with value: 0.81 and parameters: {'learning_rate': 0.022121560151363958, 'hidden_dim': 121}. Best is trial 7 with value: 0.85.\n",
      "[I 2025-09-01 11:05:39,085] Trial 9 finished with value: 0.83 and parameters: {'learning_rate': 0.002759386233580951, 'hidden_dim': 101}. Best is trial 7 with value: 0.85.\n",
      "[I 2025-09-01 11:05:41,118] Trial 10 finished with value: 0.79 and parameters: {'learning_rate': 0.00011372918104727083, 'hidden_dim': 51}. Best is trial 7 with value: 0.85.\n",
      "[I 2025-09-01 11:05:43,082] Trial 11 finished with value: 0.87 and parameters: {'learning_rate': 0.0008816299850292337, 'hidden_dim': 122}. Best is trial 11 with value: 0.87.\n",
      "[I 2025-09-01 11:05:45,014] Trial 12 finished with value: 0.865 and parameters: {'learning_rate': 0.0007859725357892634, 'hidden_dim': 57}. Best is trial 11 with value: 0.87.\n",
      "[I 2025-09-01 11:05:47,213] Trial 13 finished with value: 0.835 and parameters: {'learning_rate': 0.0010978726058086241, 'hidden_dim': 49}. Best is trial 11 with value: 0.87.\n",
      "[I 2025-09-01 11:05:49,371] Trial 14 finished with value: 0.85 and parameters: {'learning_rate': 0.00017949001217707752, 'hidden_dim': 57}. Best is trial 11 with value: 0.87.\n",
      "[I 2025-09-01 11:05:51,306] Trial 15 finished with value: 0.85 and parameters: {'learning_rate': 0.0015964139903961437, 'hidden_dim': 103}. Best is trial 11 with value: 0.87.\n",
      "[I 2025-09-01 11:05:53,206] Trial 16 finished with value: 0.845 and parameters: {'learning_rate': 0.00033008678226866765, 'hidden_dim': 62}. Best is trial 11 with value: 0.87.\n",
      "[I 2025-09-01 11:05:55,032] Trial 17 finished with value: 0.865 and parameters: {'learning_rate': 0.0016645995709214038, 'hidden_dim': 38}. Best is trial 11 with value: 0.87.\n",
      "[I 2025-09-01 11:05:56,836] Trial 18 finished with value: 0.87 and parameters: {'learning_rate': 0.0003370117464989012, 'hidden_dim': 99}. Best is trial 11 with value: 0.87.\n",
      "[I 2025-09-01 11:05:58,633] Trial 19 finished with value: 0.83 and parameters: {'learning_rate': 0.000252264937817098, 'hidden_dim': 108}. Best is trial 11 with value: 0.87.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters found:\n",
      "{'learning_rate': 0.0008816299850292337, 'hidden_dim': 122}\n"
     ]
    }
   ],
   "source": [
    "# 3. Define the objective function for Optuna\n",
    "def objective(trial):\n",
    "    # Suggest values for the hyperparameters\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-1)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 16, 128)\n",
    "\n",
    "    # Model, loss, optimizer\n",
    "    model = SimpleNN(input_dim=20, hidden_dim=hidden_dim)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Training loop\n",
    "    epochs = 20\n",
    "    batch_size = 32\n",
    "    train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(TensorDataset(X_val, y_val), batch_size=batch_size)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Validation accuracy\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in val_loader:\n",
    "            outputs = model(batch_X)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += batch_y.size(0)\n",
    "            correct += (predicted == batch_y).sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    return accuracy\n",
    "\n",
    "# 4. Run the Optuna optimization\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "# 5. Print the best hyperparameters\n",
    "print(\"Best hyperparameters found:\")\n",
    "print(study.best_params)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e44da6-fab4-4359-9883-1ff0a5f7ffcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:myenv]",
   "language": "python",
   "name": "conda-env-myenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
